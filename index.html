<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="Research on Dynamic Inference-Time Copyright Shielding with Adaptive Guidance for AI Image Generation"
    />
    <meta
      name="keywords"
      content="AI, copyright protection, image generation, diffusion models, adaptive guidance"
    />
    <meta
      name="author"
      content="Soham Roy, Abhishek Mishra, Murari Mandal, Shirish Karande"
    />
    <title>
      Guardians of Generation: Dynamic Inference-Time Copyright Shielding
    </title>
    <link rel="stylesheet" href="css/styles.css" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css"
    />
    <!-- Add Google Scholar, ORCID icons -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
  </head>
  <body>
    <header>
      <div class="container">
        <h1>Guardians of Generation</h1>
        <h2>
          Dynamic Inference-Time Copyright Shielding with Adaptive Guidance for
          AI Image Generation
        </h2>

        <div class="authors">
          <p>
            <span
              >Soham Roy<sup>1</sup
              ><a href="#" class="author-link"><i class="ai ai-orcid"></i></a
              ><a href="#" class="author-link"
                ><i class="ai ai-google-scholar"></i></a
            ></span>
            <span
              >Abhishek Mishra<sup>1</sup
              ><a href="#" class="author-link"><i class="ai ai-orcid"></i></a
              ><a href="#" class="author-link"
                ><i class="ai ai-google-scholar"></i></a
            ></span>
              <span
              >Shirish Karande<sup>3</sup
              ><a href="#" class="author-link"><i class="ai ai-orcid"></i></a
              ><a href="#" class="author-link"
                ><i class="ai ai-google-scholar"></i></a
            ></span>
            <span
              >Murari Mandal<sup>1</sup
              ><a href="#" class="author-link"><i class="ai ai-orcid"></i></a
              ><a href="#" class="author-link"
                ><i class="ai ai-google-scholar"></i></a
            ></span>

          </p>
          <p class="affiliations">
            <span
              ><sup>1</sup>RespAI Lab, KIIT University, Bhubaneswar, India</span
            >
            
            <span><sup>2</sup>TCS Research, India</span>
          </p>
          <p class="correspondence">
            <span
              >Correspondence:
              <a href="mailto:soham.respailab@gmail.com"
                >soham.respailab@gmail.com</a
              ></span
            >
          </p>
        </div>

        <div class="links">
          <a
            href="https://github.com/sohambuilds/gogpipeline"
            target="_blank"
            class="btn"
          >
            <i class="fab fa-github"></i> GitHub
          </a>
          <a
            href="https://arxiv.org/abs/xxxx.xxxxx"
            target="_blank"
            class="btn"
          >
            <i class="fas fa-file-pdf"></i> Paper (arXiv)
          </a>
          <a
            href="https://github.com/sohambuilds/gogpipeline"
            target="_blank"
            class="btn"
          >
            <i class="fas fa-code"></i> Code & Data
          </a>
        </div>
      </div>
    </header>

    <section id="section-0" class="abstract">
      <div class="container">
        <h2>Abstract</h2>
        <p>
          Modern text-to-image generative models can inadvertently reproduce
          copyrighted content memorized in their training data, raising serious
          concerns about potential copyright infringement. We introduce
          Guardians of Generation (GoG), a model-agnostic inference-time
          framework for dynamic copyright shielding in AI image generation. Our
          approach requires no retraining or modification of the generative
          model's weights, instead integrating seamlessly with existing
          diffusion pipelines. It augments the generation process with an
          adaptive guidance mechanism comprising three components: a detection
          module, a prompt rewriting module, and a guidance adjustment module.
          The detection module monitors user prompts and intermediate generation
          steps to identify features indicative of copyrighted content before
          they manifest in the final output. If such content is detected, the
          prompt rewriting mechanism dynamically transforms the user's
          prompt—sanitizing or replacing references that could trigger
          copyrighted material while preserving the prompt's intended semantics.
          The adaptive guidance module adaptively steers the diffusion process
          away from flagged content by modulating the model's sampling
          trajectory. Together, these components form a robust shield that
          enables a tunable balance between preserving creative fidelity and
          ensuring copyright compliance. We validate our method on a variety of
          generative models (Stable Diffusion 2.1, SDXL, Flux), demonstrating
          substantial reductions in copyrighted content generation with
          negligible impact on output fidelity or alignment with user intent.
          This work provides a practical, plug-and-play safeguard for generative
          image models, enabling more responsible deployment under real-world
          copyright constraints.
        </p>
      </div>
    </section>

    <section id="section-1" class="overview">
      <div class="container">
        <h2>Overview</h2>
        <div class="diagram">
          <img
            src="images/pipeline.png"
            alt="Pipeline Architecture"
            class="full-width-img"
          />
          <p class="caption">
            <strong>Figure 1:</strong> The Dynamic Inference-Time Copyright
            Shielding Pipeline. Our approach integrates concept detection,
            prompt rewriting, and adaptive guidance to balance compliance and
            creative fidelity.
          </p>
        </div>
        <p>
          Our approach introduces a novel adaptive classifier-free guidance
          mechanism that dynamically balances copyright compliance and fidelity
          to the user's intent, addressing a critical challenge in responsible
          AI deployment. The GoG framework works with existing diffusion models
          without requiring retraining, making it a practical solution for
          real-world deployment.
        </p>
      </div>
    </section>

    <section id="section-2" class="method">
      <div class="container">
        <h2>Methodology</h2>
        <div class="two-column">
          <div>
            <h3>1. Protected Concept Detection</h3>
            <p>
              We implement semantic matching between user prompts and a database
              of protected concepts, with language model verification to reduce
              false positives. Our detection mechanism identifies protected
              entities and prevents copyright infringement by monitoring both
              explicit references and indirect anchoring cues.
            </p>

            <h3>2. Prompt Rewriting</h3>
            <p>
              When protected concepts are detected, an LLM sanitizes the prompt
              while preserving non-protected elements and the user's intent.
              This maintains semantic similarity with the original prompt while
              removing potentially infringing content, ensuring the generated
              images remain aligned with user expectations.
            </p>
          </div>
          <div>
            <h3>3. Adaptive CFG</h3>
            <p>
              Our key innovation blends embeddings from original and rewritten
              prompts during the diffusion process through adaptive
              classifier-free guidance (CFG). This mechanism provides a
              continuous control spectrum between strict copyright compliance
              and creative expression.
            </p>

            <div class="formula">
              <p><strong>Formal Definition:</strong></p>
              <p>
                ε<sub>θ</sub>(x<sub>t</sub>, c) = ε<sub>θ</sub>(x<sub>t</sub>) +
                λ(αε<sub>θ</sub>(x<sub>t</sub>, c<sub>orig</sub>) +
                (1-α)ε<sub>θ</sub>(x<sub>t</sub>, c<sub>safe</sub>) -
                ε<sub>θ</sub>(x<sub>t</sub>))
              </p>
            </div>
            <p class="equation-caption">
              where <i>α</i> ∈ [0,1] is the mixing weight controlling the
              influence of original vs. rewritten prompt embeddings.
            </p>
          </div>
        </div>
      </div>
    </section>

    <section id="section-3" class="results">
      <div class="container">
        <h2>Experimental Results</h2>
        <p class="section-intro">
          We evaluated our approach on three text-to-image diffusion models
          (Stable Diffusion 2.1, SDXL, and Flux) using a diverse dataset of 33
          protected concepts across multiple categories including movie
          characters, animated figures, brand logos, and portraits. Our
          experiments demonstrate that GoG successfully balances copyright
          protection with visual quality, maintaining semantic fidelity while
          introducing sufficient visual variation to avoid infringement.
        </p>

        <div class="gallery">
          <!-- Example 1: Pikachu -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/pikachu.png"
                  alt="Original Generation of Pikachu"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_pikachu.png"
                  alt="Protected Generation of Pikachu"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Pikachu prompt comparison: "a yellow electric mouse character"
            </p>
          </div>

          <!-- Example 2: Elon Musk -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/elonmusk.png"
                  alt="Original Generation of Elon Musk"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_elonmusk.png"
                  alt="Protected Generation of Elon Musk"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Elon Musk prompt comparison: "founder of tesla presenting a car"
            </p>
          </div>

          <!-- Example 3: Mario -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/mario.png"
                  alt="Original Generation of Mario"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_mario.png"
                  alt="Protected Generation of Mario"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Mario prompt comparison: "italian plumber character with red cap"
            </p>
          </div>

          <!-- Example 4: Spiderman -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/spiderman.png"
                  alt="Original Generation of Spiderman"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_spiderman.png"
                  alt="Protected Generation of Spiderman"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Spiderman prompt comparison: "web slinging superhero fighting
              villains"
            </p>
          </div>

          <!-- Example 5: Shrek -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/shrek.png"
                  alt="Original Generation of Shrek"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_shrek.png"
                  alt="Protected Generation of Shrek"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Shrek prompt comparison: "green ogre character in swamp"
            </p>
          </div>

          <!-- Example 6: Batman -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/Batman.png"
                  alt="Original Generation of Batman"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_Batman.png"
                  alt="Protected Generation of Batman"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Batman prompt comparison: "dark vigilante with cape"
            </p>
          </div>
        </div>

        <div class="indirect-anchoring-results">
          <h3>Indirect Anchoring Protection</h3>
          <p>
            A key challenge in copyright protection is addressing indirect
            anchoring—where prompts use descriptive cues rather than explicitly
            naming protected entities. Our experiments with cartoon and animated
            characters demonstrate that GoG effectively mitigates these
            vulnerabilities. At a guidance scale (η) of 3.0 and mixing weight
            (α) of 0.7, we achieved a balanced protection profile with optimal
            CLIP-I (0.84), CLIP-T (0.22), and SSIM (0.50) scores, while
            significantly reducing detected instances of copyright infringement.
          </p>
          <div class="diagram">
            <img
              src="images/indirect_anchoring.png"
              alt="Indirect Anchoring Comparison"
              class="full-width-img"
            />
            <p class="caption">
              <strong>Figure 3:</strong> Without GoG, models produce copyrighted
              images even when prompts lack explicit references (top row). Our
              approach prevents generating protected content while preserving
              the prompt's semantics (bottom row).
            </p>
          </div>
        </div>
      </div>
    </section>

    <section id="section-4" class="evaluation-metrics">
      <div class="container">
        <h2>Evaluation Metrics</h2>
        <p class="section-intro">
          We evaluated our method using six key metrics that measure both
          semantic fidelity and copyright protection:
        </p>
        <ul class="research-list">
          <li>
            <strong>CLIP-I & CLIP-T:</strong> Measure semantic alignment between
            generated images, original copyrighted content, and user prompts
          </li>
          <li>
            <strong>LPIPS:</strong> Quantifies perceptual similarity between
            original and protected images
          </li>
          <li><strong>SSIM:</strong> Assesses structural similarity</li>
          <li>
            <strong>CONS:</strong> Employs a VQA model to determine if key
            visual features of target concepts are present
          </li>
          <li>
            <strong>DETECT:</strong> Counts occurrences of target entities to
            measure unintended replication
          </li>
        </ul>
        <p>
          Our experiments show that the GoG framework achieves a balanced range
          of metrics across different models, with moderate CLIP-I (0.66-0.85),
          CLIP-T (0.15-0.25), LPIPS (0.40-0.60), and SSIM (0.30-0.40) values.
          This indicates generated images that remain semantically aligned with
          user intent while avoiding direct copyright infringement.
        </p>
      </div>
    </section>

    <section id="section-5" class="mixing-weights">
      <div class="container">
        <h2>Parametric Analysis: Effect of Mixing Weight (α)</h2>
        <p class="section-intro">
          The mixing weight parameter allows fine control over the balance
          between copyright protection and visual fidelity. Our experiments
          across different models show that optimal α values typically fall
          between 0.65-0.75, providing effective copyright protection while
          maintaining high image quality.
        </p>
        <div class="diagram">
          <img
            src="images/Transition.png"
            alt="Mixing Weight Comparison"
            class="full-width-img"
          />
          <p class="caption">
            <strong>Figure 2:</strong> Transition of generated images with
            different mixing weights (α). Higher values of α allow more
            influence from the rewritten prompt, while lower values favor the
            original prompt. Analysis conducted over 500 prompt pairs.
          </p>
        </div>
        <p>Our results indicate different optimal parameters across models:</p>
        <ul class="research-list">
          <li>
            <strong>Stable Diffusion 2.1:</strong> Best results at guidance
            scale (η) of 8.0 with mixing weight (α) of 0.5
          </li>
          <li>
            <strong>SDXL:</strong> Optimal performance at η=3.0 with α=0.5 or
            α=0.7
          </li>
          <li>
            <strong>Flux:</strong> Most effective at η=3.0 with α=0.7 for
            indirect anchoring scenarios
          </li>
        </ul>
        <p>
          These findings highlight that while the general approach is
          consistent, fine-tuning parameters for specific models can further
          optimize the balance between copyright protection and image quality.
        </p>
      </div>
    </section>

    <section id="section-6" class="limitations">
      <div class="container">
        <h2>Limitations and Future Work</h2>
        <p>
          While our approach demonstrates promising results, several limitations
          remain. The method relies on a pre-defined database of protected
          concepts, which may not cover all copyrighted materials. Additionally,
          the effectiveness of prompt rewriting depends on the capabilities of
          the language model used.
        </p>

        <h3>Performance Considerations</h3>
        <p>
          GoG introduces computational overhead that affects generation time:
        </p>
        <ul class="research-list">
          <li>
            <strong>SD 2.1:</strong> 35.84s without GoG vs. 185.27s with GoG
          </li>
          <li>
            <strong>SDXL:</strong> 38.92s without GoG vs. 187.77s with GoG
          </li>
          <li>
            <strong>Flux:</strong> 56.63s without GoG vs. 251.02s with GoG
          </li>
        </ul>
        <p>
          These measurements were conducted on a single NVIDIA A6000 GPU. While
          the additional processing time is significant, the improved control
          over copyright compliance justifies this overhead for many
          applications.
        </p>

        <h3>Future Work</h3>
        <p>Future research will focus on:</p>
        <ul class="research-list">
          <li>
            Developing more comprehensive protected concept detection through
            active learning
          </li>
          <li>Extending the approach to video generation models</li>
          <li>
            Exploring personalized α parameter settings based on user
            preferences and risk profiles
          </li>
          <li>
            Investigating cross-modal copyright detection between text and
            visual domains
          </li>
          <li>Optimizing performance to reduce computational overhead</li>
        </ul>
      </div>
    </section>

    <section id="section-7" class="citation">
      <div class="container">
        <h2>Citation</h2>
        <div class="bibtex">
          <pre>
@article{roy2025guardians,
    title={Guardians of Generation: Dynamic Inference-Time Copyright Shielding with Adaptive Guidance for AI Image Generation},
    author={Roy, Soham and Mandal, Murari and Mishra, Abhishek and Karande, Shirish},
    journal={arXiv preprint arXiv:xxxx.xxxxx},
    year={2025},
    doi={10.xxxx/xxxxx.xxxxx}
}
                </pre
          >
        </div>
      </div>
    </section>

    <footer>
      <div class="container">
        <p>&copy; 2025 RespAI Lab. All rights reserved.</p>
        <p class="last-updated">Last updated: March 2023</p>
      </div>
    </footer>

    <button id="back-to-top" class="back-to-top" aria-label="Back to top">
      <i class="fas fa-arrow-up"></i>
    </button>

    <script src="js/main.js"></script>
  </body>
</html>
