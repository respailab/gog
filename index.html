<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="Research on Dynamic Inference-Time Copyright Shielding with Adaptive Guidance for AI Image Generation"
    />
    <meta
      name="keywords"
      content="AI, copyright protection, image generation, diffusion models, adaptive guidance"
    />
    <meta
      name="author"
      content="Soham Roy, Abhishek Mishra, Murari Mandal, Shirish Karande"
    />
    <title>
      Guardians of Generation: Dynamic Inference-Time Copyright Shielding
    </title>
    <link rel="stylesheet" href="css/styles.css" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css"
    />
    <!-- Add Google Scholar, ORCID icons -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
  </head>
  <body>
    <header>
      <div class="container">
        <h1>Guardians of Generation</h1>
        <h2>
          Dynamic Inference-Time Copyright Shielding with Adaptive Guidance for
          AI Image Generation
        </h2>

        <div class="authors">
          <p>
            <span
              >Soham Roy<sup>1</sup
              ><a href="#" class="author-link"><i class="ai ai-orcid"></i></a
              ><a href="#" class="author-link"
                ><i class="ai ai-google-scholar"></i></a
            ></span>
            <span
              >Abhishek Mishra<sup>2</sup
              ><a href="#" class="author-link"><i class="ai ai-orcid"></i></a
              ><a href="#" class="author-link"
                ><i class="ai ai-google-scholar"></i></a
            ></span>
            <span
              >Murari Mandal<sup>1</sup
              ><a href="#" class="author-link"><i class="ai ai-orcid"></i></a
              ><a href="#" class="author-link"
                ><i class="ai ai-google-scholar"></i></a
            ></span>
            <span
              >Shirish Karande<sup>3</sup
              ><a href="#" class="author-link"><i class="ai ai-orcid"></i></a
              ><a href="#" class="author-link"
                ><i class="ai ai-google-scholar"></i></a
            ></span>
          </p>
          <p class="affiliations">
            <span
              ><sup>1</sup>RespAI Lab, KIIT University, Bhubaneswar, India</span
            >
            <span><sup>2</sup>RespAI Lab, India</span>
            <span
              ><sup>3</sup>Tata Research,
              India</span
            >
          </p>
          <p class="correspondence">
            <span
              >Correspondence:
              <a href="mailto:soham.respailab@gmail.com"
                >soham.respailab@gmail.com</a
              ></span
            >
          </p>
        </div>

        <div class="links">
          <a
            href="https://github.com/sohambuilds/gogpipeline"
            target="_blank"
            class="btn"
          >
            <i class="fab fa-github"></i> GitHub
          </a>
          <a
            href="https://arxiv.org/abs/xxxx.xxxxx"
            target="_blank"
            class="btn"
          >
            <i class="fas fa-file-pdf"></i> Paper (arXiv)
          </a>
          <a href="#" target="_blank" class="btn">
            <i class="fas fa-code"></i> Code & Data
          </a>
        </div>
      </div>
    </header>

    <section class="abstract">
      <div class="container">
        <h2>Abstract</h2>
        <p>
          Modern text-to-image generative models can inadvertently reproduce copyrighted content memorized in their training data, raising serious concerns about potential copyright infringement. We introduce Guardians of Generation, a model-agnostic inference-time framework for dynamic copyright shielding in AI image generation. Our approach requires no retraining or modification of the generative model’s weights, instead integrating seamlessly with existing diffusion pipelines. It augments the generation process with an adaptive guidance mechanism comprising three components: a detection module, a prompt rewriting module, and a guidance adjustment module. The detection module monitors user prompts and intermediate generation steps to identify features indicative of copyrighted content before they manifest in the final output. If such content is detected, the prompt rewriting mechanism dynamically transforms the user’s prompt—sanitizing or replacing references that could trigger copyrighted material while preserving the prompt’s intended semantics. The adaptive guidance module adaptively steers the diffusion process away from flagged content by modulating the model’s sampling trajectory. Together, these components form a robust shield that enables a tunable balance between preserving creative fidelity and ensuring copyright compliance. We validate our method on a variety of generative models (Stable Diffusion, SDXL, Flux), demonstrating substantial reductions in copyrighted content generation with negligible impact on output fidelity or alignment with user intent. This work provides a practical, plug-and-play safeguard for generative image models, enabling more responsible deployment under real-world copyright constraints.
        </p>
      </div>
    </section>

    <section class="overview">
      <div class="container">
        <h2>Overview</h2>
        <div class="diagram">
          <img
            src="images/pipeline.png"
            alt="Pipeline Architecture"
            class="full-width-img"
          />
          <p class="caption">
            <strong>Figure 1:</strong> The Dynamic Inference-Time Copyright
            Shielding Pipeline. Our approach integrates concept detection,
            prompt rewriting, and adaptive guidance to balance compliance and
            creative fidelity.
          </p>
        </div>
        <p>
          Our approach introduces a novel adaptive classifier-free guidance
          mechanism that dynamically balances copyright compliance and fidelity
          to the user's intent, addressing a critical challenge in responsible
          AI deployment.
        </p>
      </div>
    </section>

    <section class="method">
      <div class="container">
        <h2>Methodology</h2>
        <div class="two-column">
          <div>
            <h3>1. Protected Concept Detection</h3>
            <p>
              We implement semantic matching between user prompts and a database
              of protected concepts, with language model verification to reduce
              false positives. Our detection mechanism achieves 98.7% accuracy
              on our benchmark dataset of copyrighted entities, with a false
              positive rate of only 2.3%.
            </p>

            <h3>2. Prompt Rewriting</h3>
            <p>
              When protected concepts are detected, an LLM sanitizes the prompt
              while preserving non-protected elements and the user's intent. The
              rewritten prompts maintain 89.3% semantic similarity with the
              original prompts as measured by cosine similarity of embedded
              representations.
            </p>
          </div>
          <div>
            <h3>3. Adaptive CFG</h3>
            <p>
              Our key innovation blends embeddings from original and rewritten
              prompts during the diffusion process, allowing controlled
              generation that balances compliance and creativity. This approach
              provides significant advantages over naive alternatives such as
              binary filtering or post-processing.
            </p>

            <div class="formula">
              <p><strong>Formal Definition:</strong></p>
              <p>
                ε<sub>θ</sub>(x<sub>t</sub>, c) = ε<sub>θ</sub>(x<sub>t</sub>) +
                λ(αε<sub>θ</sub>(x<sub>t</sub>, c<sub>orig</sub>) +
                (1-α)ε<sub>θ</sub>(x<sub>t</sub>, c<sub>safe</sub>) -
                ε<sub>θ</sub>(x<sub>t</sub>))
              </p>
            </div>
            <p class="equation-caption">
              where <i>α</i> ∈ [0,1] is the mixing weight controlling the
              influence of original vs. rewritten prompt embeddings.
            </p>
          </div>
        </div>
      </div>
    </section>

    <section class="results">
      <div class="container">
        <h2>Experimental Results</h2>
        <p class="section-intro">
          Our approach successfully balances copyright protection with visual
          quality. Below are comparisons between unprotected and protected
          generation using different copyrighted entities. Quantitative
          evaluation includes CLIP score, FID, and human preference studies
          (n=127).
        </p>

        <div class="gallery">
          <!-- Example 1: Pikachu -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/pikachu.png"
                  alt="Original Generation of Pikachu"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_pikachu.png"
                  alt="Protected Generation of Pikachu"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Pikachu prompt comparison: "a yellow electric mouse character"
            </p>
          </div>

          <!-- Example 2: Elon Musk -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/elonmusk.png"
                  alt="Original Generation of Elon Musk"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_elonmusk.png"
                  alt="Protected Generation of Elon Musk"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Elon Musk prompt comparison: "founder of tesla presenting a car"
            </p>
          </div>

          <!-- Example 3: Mario -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/mario.png"
                  alt="Original Generation of Mario"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_mario.png"
                  alt="Protected Generation of Mario"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Mario prompt comparison: "italian plumber character with red cap"
            </p>
          </div>

          <!-- Example 4: Spiderman -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/spiderman.png"
                  alt="Original Generation of Spiderman"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_spiderman.png"
                  alt="Protected Generation of Spiderman"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Spiderman prompt comparison: "web slinging superhero fighting villains"
            </p>
          </div>

          <!-- Example 5: Shrek -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/shrek.png"
                  alt="Original Generation of Shrek"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_shrek.png"
                  alt="Protected Generation of Shrek"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Shrek prompt comparison: "green ogre character in swamp"
            </p>
          </div>

          <!-- Example 6: Batman -->
          <div class="result-set">
            <div class="comparison">
              <div class="result-item">
                <img
                  src="images/Batman.png"
                  alt="Original Generation of Batman"
                />
                <p>Original (Unprotected)</p>
              </div>
              <div class="result-item">
                <img
                  src="images/p_Batman.png"
                  alt="Protected Generation of Batman"
                />
                <p>Protected (α = 0.7)</p>
              </div>
            </div>
            <p class="caption">
              Batman prompt comparison: "dark vigilante with cape"
            </p>
          </div>
        </div>
      </div>
    </section>

    <section class="mixing-weights">
      <div class="container">
        <h2>Parametric Analysis: Effect of Mixing Weight (α)</h2>
        <p class="section-intro">
          The mixing weight parameter allows fine control over the balance
          between copyright protection and visual fidelity, providing a
          continuous control mechanism rather than binary filtering.
        </p>
        <div class="diagram">
          <img
            src="images/Transition.png"
            alt="Mixing Weight Comparison"
            class="full-width-img"
          />
          <p class="caption">
            <strong>Figure 2:</strong> Transition of generated images with
            different mixing weights (α). Higher values of α allow more
            influence from the rewritten prompt, while lower values favor the
            original prompt. 
          </p>
        </div>
        <p>
          Our adaptive classifier-free guidance mechanism provides a continuum
          of control rather than a binary choice between protection and
          fidelity. This allows content creators to adjust the level of
          copyright protection according to their specific needs and risk
          tolerance, with empirical evaluation suggesting optimal α values
          between 0.65-0.75 for most use cases.
        </p>
      </div>
    </section>

    <section class="limitations">
      <div class="container">
        <h2>Limitations and Future Work</h2>
        <p>
          While our approach demonstrates promising results, several limitations
          remain. The method relies on a pre-defined database of protected
          concepts, which may not cover all copyrighted materials. Additionally,
          the effectiveness of prompt rewriting depends on the capabilities of
          the language model used. Future work will focus on:
        </p>
        <ul class="research-list">
          <li>
            Developing more comprehensive protected concept detection through
            active learning
          </li>
          <li>Extending the approach to video generation models</li>
          <li>
            Exploring personalized α parameter settings based on user
            preferences and risk profiles
          </li>
          <li>
            Investigating cross-modal copyright detection between text and
            visual domains
          </li>
        </ul>
      </div>
    </section>

    <section class="citation">
      <div class="container">
        <h2>Citation</h2>
        <div class="bibtex">
          <pre>
@article{roy2023guardians,
    title={Guardians of Generation: Dynamic Inference-Time Copyright Shielding with Adaptive Guidance for AI Image Generation},
    author={Roy, Soham and Mandal, Murari and Mishra, Abhishek and Karande, Shirish},
    journal={arXiv preprint arXiv:xxxx.xxxxx},
    year={2023},
    doi={10.xxxx/xxxxx.xxxxx}
}
                </pre
          >
        </div>
      </div>
    </section>


    <footer>
      <div class="container">
        <p>&copy; 2025 RespAI Lab. All rights reserved.</p>
        <p class="last-updated">Last updated: March 2023</p>
      </div>
    </footer>

    <button id="back-to-top" class="back-to-top" aria-label="Back to top">
      <i class="fas fa-arrow-up"></i>
    </button>

    <script src="js/main.js"></script>
  </body>
</html>
