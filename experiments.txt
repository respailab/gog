\begin{figure*}[t]
    \centering
    \includegraphics[width=0.8\textwidth]
    {Images/Indirect_anchoring-2.png}
    \caption{We use indirect anchoring as a potential jailbreak mechanism. Without our \textbf{GoG}, the model produces copyrighted images even when the prompt lacks explicit references (1st row). In contrast, our approach prevents generating protected content while preserving the prompt’s semantics (2nd row), underscoring its robustness against indirect anchoring vulnerabilities}
    \vspace{-1\baselineskip}
    \label{fig:indirect_anchoring}
\end{figure*}


\begin{table}[t]
    \centering
    \small
    %\resizebox{\columnwidth}{!}{
    \scalebox{0.8}{
    \begin{tabular}{cccccc} % 6 columns
        \toprule
        $\eta$ & SSIM & LPIPS & CLIP-I & CLIP-T\\ 
        \toprule
        2.0 &  0.16 & 0.65 & 0.66 & 0.17 \\
        \midrule
       3.0 &  0.18 & 0.66 & 0.66 & \textbf{0.17} \\
        \midrule
       4.0 &  0.20 & 0.65 & 0.67 & 0.16 \\
        \midrule
       5.0 &  0.21 & 0.67 & 0.68 & 0.16 \\
        \midrule
        6.0 &  0.21 & 0.66 & 0.69 & 0.16 \\
        \midrule
       7.0  &  0.22 & 0.66 & 0.69 & 0.16 \\
        \midrule
       8.0  & \textbf{0.23} & \textbf{0.67} & \textbf{0.70} & 0.16 \\
        \bottomrule
    \end{tabular}
    }
    %}
    \caption{\textbf{GoG} performance on SD 2.1 at different guidance scale $\eta$ and mixing weight $\alpha=0.5$}
    \label{tab:SD21_guidance_mix_weight}
    \vspace{-1\baselineskip}
\end{table}

\begin{table}[t]
    \centering
    %\resizebox{\columnwidth}{!}{
    \scalebox{0.7}{
    \begin{tabular}{cccccc} % 8 columns
        \toprule
         $\eta$ & $\alpha$ & SSIM & LPIPS & CLIP-I & CLIP-T  \\ 
        \toprule
        \multirow{2}{*}{2.0} & 0.5 & 0.21 & 0.55 & 0.78 & 0.17 \\
            & 0.7 & 0.22 & 0.56 & 0.76 & 0.17 \\
        \midrule
        \multirow{2}{*}{3.0} & 0.5 & \textbf{0.22} & 0.56 & 0.80 &\textbf{ 0.17} \\
            & 0.7 & 0.22 & 0.56 & 0.76 & 0.17 \\
        \midrule
        \multirow{2}{*}{4.0} & 0.5 & 0.21 & 0.55 & 0.81 & 0.17 \\
            & 0.7 & 0.21 & 0.57 & 0.77 & 0.17 \\
        \midrule
        \multirow{2}{*}{5.0} & 0.5 & 0.21 & 0.57 & 0.82 & 0.17 \\
            & 0.7 & 0.21 & 0.57 & 0.77 & 0.16 \\ 
        \midrule
        \multirow{2}{*}{6.0} & 0.5 & 0.2 & 0.57 & 0.82 & 0.16 \\
            & 0.7 & 0.20 & 0.58 & 0.77 & 0.16 \\
        \midrule
       \multirow{2}{*}{7.0}  & 0.5 & 0.19 & 0.57 & 0.83 & 0.16 \\
            & 0.7 & 0.19 & 0.58 & 0.77 & 0.16 \\
        \midrule
       \multirow{2}{*}{8.0}  & 0.5 & 0.19 & 0.57 & \textbf{0.83} & 0.16 \\
            & 0.7 & 0.18 & \textbf{0.59} & 0.79 & 0.16 \\
        \bottomrule
    \end{tabular}
    %}
    }
    \caption{\textbf{GoG} performance on SDXL at different guidance scale $\eta$ and mixing weights $\alpha$}
    \label{tab:SDXL_guidance_mix_weight}
    \vspace{-1\baselineskip}
\end{table}

\section{Experiments and Results} 
\textbf{Experiment Settings.} We perform experiments on three text-to-image generative models: Stable Diffusion 2.1~\cite{sd}, Stable Diffusion XL~\cite{sdxl}, and Flux~\cite{blackforestlabs2024flux}. To evaluate copyright protection, we assemble a diverse set of 33 protected concepts spanning various categories, including movie characters, animated figures, video game protagonists, brand logos, portraits of actors and singers, art styles, and famous paintings. For each concept, we establish semantic and entity relationships by incorporating synonyms and related references. Additionally, three prompt variants of different lengths are generated per concept (see Table~\ref{tab:distri_prompt_len}). For each prompt, we sampled 4 images across 7 different guidance scales. 
%See Table~\ref{table:1}.

% We conduct experiments on three different text-to-image diffusion models: Stable Diffusion 2.1~\cite{sd}, Stable Diffusion XL~\cite{sdxl} and Flux~\cite{blackforestlabs2024flux}. To evaluate copyright protection, we construct a diverse set of protected concepts. We select 33 distinct concepts spanning various categories, including movie characters, animated figures, video game protagonists, brand logos, portraits of actors and singers, art styles, and famous paintings. For each concept, we establish semantic and entity relationships, incorporating synonyms and related references. For each concept we generated 3 different sized prompts. 

% \begin{table*}[t]
%     \begin{adjustbox}{width=\textwidth,center}
%     \begin{tabular}[h]{c|cccccc|cccccc}
%     \hline
%     \multicolumn{7}{c}{\textbf{Flux}} & \multicolumn{6}{c}{\textbf{SDXL}} \\
%     \hline
%     \textbf{G.S.} & \textbf{SSIM} & \textbf{LPIPS} & \textbf{CLIP-I} & \textbf{CLIP-T} & \textbf{PSNR} & \textbf{VIF} & \textbf{SSIM} & \textbf{LPIPS} & \textbf{CLIP-I} & \textbf{CLIP-T} & \textbf{PSNR} & \textbf{VIF} \\
%     \hline
%     2.0 & 0.3562 & 0.5541 & 0.8237 & 0.153 & 0.1174 & 10.328 & 0.2143 &	0.5518 & 0.7831 & 0.1715 & 0.0747 & 12.2642 \\
%     3.0 & 0.3573 & 0.554 & 0.8239 & 0.153 & 0.1096 & 9.6786 & 0.2188 & 0.5564 & 0.76805 & 0.1676 & 0.072 & 11.716 \\
%     4.0 & 0.3303 & 0.5599 & 0.8176 & 0.1538 & 0.1073 & 9.0202 & 0.2115 &	0.5593 & 0.79855 & 0.166 & 0.0714 & 11.1356 \\
%     5.0 & 0.3282 & 0.5738 & 0.7983 & 0.1545 & 0.099 & 8.7822 & 0.2084 &	0.5639 & 0.8188 & 0.1646 & 0.0682 & 10.6886 \\
%     6.0 & 0.3269 & 0.5846 & 0.7868 & 0.1574 & 0.0922 & 8.5656 & 0.1992 & 0.5626 & 0.8005 & 0.1639 & 0.0651 & 10.3512 \\
%     7.0 & 0.3255 & 0.5752 & 0.7954 & 0.1542 & 0.0959 & 8.7999 & 0.1944 & 0.5689 & 0.78145 & 0.1632 & 0.0622 & 9.9834 \\
%     8.0 & 0.3484 & 0.5692 & 0.8029 & 0.1542 & 0.09654 & 8.8069 & 0.1898	& 0.5861 & 0.80925 & 0.1627 & 0.0616 & 9.7098 \\
%     \hline
%     \end{tabular}
%     \end{adjustbox}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table*}


\begin{table}[t]
    \centering
    \small
    %\resizebox{\columnwidth}{!}{
    \scalebox{0.8}{
    \begin{tabular}[h!]{c c c c cc} % 6 columns
        \toprule
        $\eta$ & $\alpha$ & SSIM & LPIPS & CLIP-I & CLIP-T \\ 
        \toprule
        \multirow{2}{*}{2.0} & 0.5  & 0.36 & 0.55 & 0.85 & 0.15 \\ 
            & 0.65 & 0.36 & 0.56 & 0.79 & 0.15 \\ 
        \midrule
        \multirow{2}{*}{3.0} & 0.5  & \textbf{0.36} & 0.54 & \textbf{0.85} & \textbf{0.16} \\ 
            & 0.65 & 0.35 & 0.57 & 0.80 & 0.15 \\ 
        \midrule
        \multirow{2}{*}{4.0} & 0.5  & 0.34 & 0.55 & 0.84 & 0.16 \\ 
            & 0.65 & 0.33 & 0.57 & 0.79 & 0.15 \\ 
        \midrule
        \multirow{2}{*}{5.0} & 0.5  & 0.33 & 0.56 & 0.82 & 0.16 \\ 
            & 0.65 & 0.32 & \textbf{0.59} & 0.78 & 0.15 \\ 
        \bottomrule
       %  6.0 & 0.5  & 0.3279 & 0.5786 & 0.8120 & 0.1585 \\ 
       %      & 0.65 & 0.3258 & 0.5906 & 0.7617 & 0.1562 \\ 
       %  \hline
       % 7.0 & 0.5  & 0.3291 & 0.5661 & 0.8173 & 0.1555 \\ 
       %     & 0.65 & 0.3219 & 0.5843 & 0.7734 & 0.1531 \\ 
       %  \hline
       % 8.0 & 0.5  & 0.356 & 0.5573 & 0.8286 & 0.1552 \\ 
       %     & 0.65 & 0.3407 & 0.5812 & 0.7773 & 0.1531 \\ 
       %  \hline
    \end{tabular}
    }
    %}
    \caption{\textbf{GoG} performance on FLUX at different guidance scale $\eta$ and mixing weights $\alpha$}
    \label{tab:Flux_evaluation}
    \vspace{-1\baselineskip}
\end{table}


\begin{table}[t]
    \centering
    \resizebox{\columnwidth}{!}{
    \begin{tabular}[h]{c|ccc|ccc}
    \toprule
    & \multicolumn{3}{c}{SDXL} & \multicolumn{3}{c}{FLUX} \\
    \midrule
    $\eta$ & $CONS_{unpro}$ & $CONS_{\alpha=0.7}$ & DETECT & $CONS_{unpro}$ & $CONS_{\alpha=0.65}$ & DETECT \\
    \midrule
    2.0 & 0.46& 0.44 & 1 & 0.42&0.47 &  7\\
    3.0 & 0.43&0.50 & 1 & 0.41&0.44 &  4\\
    4.0 & 0.46&0.46 & 2 & 0.41&0.44 &  4\\
    5.0 & 0.46&0.47 & 4 & 0.41&0.46 & 3\\
    6.0 & 0.42&0.48 & 2 & 0.39&0.46 & 3\\
    7.0 & 0.44&0.46 & 9 & 0.38&0.42 & 6 \\
    8.0 & 0.43&0.44 & 1 & 0.42&0.47 & 4 \\
    \bottomrule
    \end{tabular}
    }
    %\end{adjustbox}
    \caption{CONS and DETECT scores on Flux and SDXL models. We compare the CONS metric with and without GoG protection.}
    \label{tab:copycat_comp}
    \vspace{-1\baselineskip}
\end{table}

% \begin{table}[t]
%     \centering
%     \begin{adjustbox}{width=\columnwidth,center}
%     \begin{tabular}[h]{c|cc|cc}
%     \toprule
%     & \multicolumn{2}{c}{SDXL} & \multicolumn{2}{c}{FLUX} \\
%     \midrule
%     $\eta$ & $\mathrm{CONS}_{\mathrm{unpro}}$ & $\mathrm{CONS}_{\mathrm{\alpha= 0.7}}$ & $\mathrm{CONS}_{\mathrm{unpro}}$ & $\mathrm{CONS}_{\mathrm{\alpha=0.65}}$ \\
%     \midrule
%     2.0 & 0.46 & 0.44 & 0.42 & 0.47 \\
%     3.0 & 0.43 & 0.5 & 0.41 & 0.44 \\
%     4.0 & 0.46 & 0.46 & 0.41 & 0.44 \\
%     5.0 & 0.46 & 0.47 & 0.41 & \textbf{0.46} \\
%     6.0 & 0.42 & 0.48 & 0.39 & 0.46 \\
%     7.0 & 0.44 & 0.46 & 0.38 & 0.42 \\
%     8.0 & 0.43 & \textbf{0.44 }& 0.42 & 0.47 \\
%     \bottomrule
%     \end{tabular}
%     \end{adjustbox}
%     \caption{Comparison of the consistency (CONS) metric for original generation using the baseline FLUX and SDXL models versus the proposed method \textbf{CoG}.}
%     \label{tab:baseline_VS_Cog_cons}
% \end{table}

\noindent
\textbf{Metrics} We evaluate the degree of copyright protection with six metrics CLIP-I, CLIP-T, LPIPS, SSIM, CONS, DETECT \cite{2025fantastic}. When evaluating the effectiveness of copyright protection in AI-generated images, it is crucial to interpret similarity metrics within a balanced, intermediate range. Metrics such as CLIP-I, CLIP-T, and LPIPS quantify semantic and perceptual alignment between the generated image, the original copyrighted image, and the user's textual prompt. Extremely high values of these metrics suggest minimal modifications, risking copyright infringement, while excessively low values indicate significant deviation from the intended visual style or user request, diminishing utility. Thus, for effective copyright protection that also partially satisfies the user's intent, these metrics should ideally lie within a moderate, balanced range. We also employ CONS, a VQA model~\cite{lin2024evaluating} that checks for key visual features in the generated image, and DETECT, which counts occurrences of target entities to measure unintended replication~\cite{2025fantastic}.\par

% Empirically, we find a reasonable guideline for this balance is maintaining CLIP-I, CLIP-T, LPIPS, SSIM within approximately 0.65–0.85, 0.15-0.25, 0.40-0.60, 0.30-0.40 range, respectively.

% Within this range, the generated images retain meaningful resemblance to the user's query and the original style, yet remain sufficiently distinct to avoid infringement, effectively striking a balance between copyright compliance and user satisfaction.

% We also use the metrics proposed in~\cite{2025fantastic}, CONS (consistency) which employs a VQA model to determine whether the key visual features of the target concept are present in the generated image; and 6) DETECT, also from CopyCat, which quantifies unintended replication by detecting and counting occurrences of target entities. Together, these metrics provide a holistic assessment of our method's ability to maintain high-quality, semantically accurate, and structurally sound outputs while mitigating the risk of copyright infringement.\\ 

\noindent
\textbf{Dataset} We built a dataset across four domains: cartoon/animated characters (11 targets), famous movie stars/singers/people (8 targets), brand logos (8 targets), and famous paintings (6 targets). For each target, three prompts were generated, from simple (e.g., ``Show me a Mario'') to elaborate (e.g., ``An intricate scene featuring Pikachu leading a group of diverse Pokémon through a challenging forest filled with obstacles and hidden Pokéballs''), to test how prompt complexity affects consistency and potential IP infringement (see Table~\ref{tab:distri_prompt_len} for prompt's length distribution in our dataset). Overall, the dataset includes 99 diverse prompts. For indirect anchoring, we focused on the 11 cartoon characters, using descriptive cues instead of explicit names. We observed that all three base models produced copyrighted images even when the target name was omitted. Following~\cite{2025fantastic}, although the outputs aligned with the prompts, the generated images were too similar to the original copyrighted concepts (see Figure~\ref{fig:front_page} and Figure~\ref{fig:indirect_anchoring}).\par

\textbf{Balancing semantic fidelity with visual variation:} Our evaluation indicates that the generated images maintain strong semantic fidelity with the user’s prompt, as evidenced by consistent CLIP-T scores (0.15–0.17) across models. At the same time, perceptual and structural modifications vary by model. For instance, LPIPS scores for SD2.1 and SDXL (0.16–0.22) (see Table~\ref{tab:SD21_guidance_mix_weight} and Table~\ref{tab:SDXL_guidance_mix_weight}) suggest high perceptual similarity, while Flux’s higher LPIPS (0.32–0.36) (see Table~\ref{tab:Flux_evaluation}) indicates a greater degree of visual deviation. SSIM results further show that SD2.1 (0.65–0.67) retains more of the original structure compared to SDXL and Flux (0.55–0.59), and CLIP-I values (ranging from 0.66–0.85) reflect a moderate image-to-image similarity that helps balance between retaining desired visual cues and avoiding excessive replication of copyrighted details.\par

Overall, these metrics suggest that GoG successfully achieves the desired balance: the outputs remain consistent with the intended semantic message while introducing sufficient perceptual and structural modifications to mitigate direct copying risks. In this context, although SD2.1 and SDXL produce images that are more visually similar to the originals, Flux’s approach offers a greater degree of deviation. This outcome implies that the generated images align well with the user’s initial intention without being too similar to the copyrighted content, thereby meeting our goal of avoiding infringement while preserving semantic integrity (see Figure~\ref{fig:celeb}).

\textbf{Why do we get different scores than~\cite{2025fantastic} but similar effect?} We used prompts like ``Show me a Spiderman'' to encourage varied artistic outputs, while~\cite{2025fantastic} used the target name directly, resulting in images focused on key features. Our direct prompts show lower consistency due to creative variability. In contrast, indirect prompting with richer descriptions of key features boosted consistency (score = 0.74 with only 3 instances detected), indicating that detailed prompts help the model better replicate intended features (see Table~\ref{tab:copycat_comp}).

% \textbf{Comparison with method in~\cite{2025fantastic}:} In our experiments, we used prompts such as ``Show me a Spiderman'' to guide the image generation process. This instructive phrasing encourages the model to produce outputs with varied backgrounds and artistic interpretations, thereby allowing for a degree of creative freedom. In contrast,~\cite{2025fantastic} used the target concept itself (e.g., “Spiderman”) as the prompt, resulting in images that are more narrowly focused on the key features of the character. Consequently, our direct prompts tend to yield lower consistency scores because the broader creative scope introduces variability in how the target entity is rendered. Furthermore, when employing indirect prompting—where the prompt is extended to be more descriptive about the key features of the target concept—we observed a significant increase in consistency. Specifically, our indirect prompting approach achieved a consistency score of approximately 0.74 with only 3 instances detected, suggesting that when the prompt provides richer semantic context, the model is better able to replicate the intended features in the generated image. This contrast indicates that simple prompts like “Show me a SpiderMan” leave ample room for creativity, which in turn reduces consistency relative to more detailed, descriptive prompts or prompt-rewriting methods.

\textbf{Indirect anchoring analysis:} We conducted experiments with the Flux model on cartoon and animated characters, which inherently possess rich visual features that descriptive prompts can capture without relying on associative cues (see Figure~\ref{fig:indirect_anchoring}). Unlike celebrity or brand domains, where indirect prompts might use terms like ``Swifty'' for Taylor Swift or ``CEO of X'' for Elon Musk, cartoon characters have intrinsic attributes (unique body shapes, facial expressions, color schemes) that allow for clearer evaluations. Our findings indicate that a guidance scale ($\eta$) of 0.3 is optimal for generating high-quality images, as higher levels led to blurring even with high-resolution cues like ``4K'' or ``UHD'' (see Table~\ref{tab:Flux_indirect_anchoring}). Additionally, a mixing weight ($\alpha$) of 0.7 balanced consistency and protection against generating overly similar copyrighted images, achieving a CLIP-I score of approximately 0.84 between protected and unprotected images (see Figure~\ref{fig:transition}). These results validate our indirect anchoring method: descriptive prompts that emphasize key visual traits enable the model to accurately capture cartoon characters’ essence while mitigating direct associations that could lead to copyright infringement.

% \textbf{Indirect anchoring analysis:} 
% Our indirect anchoring experiment was conducted using the Flux model exclusively on cartoon and animated characters. We selected this domain because these characters inherently possess rich, distinctive visual features that can be captured using descriptive prompts—without relying on associative cues. In domains such as celebrity or brand recognition, prompts often require additional associative language (for example, using “Swifty” for Taylor Swift or “CEO of X” for Elon Musk) to indirectly reference the target. However, these external associations can be easily flagged by our detection pipeline using our concept dataset, which includes well-known synonyms and related phrases. By concentrating on cartoon characters, we avoid such indirect cues and instead leverage their intrinsic, feature-dense attributes (such as unique body shapes, facial expressions, and color schemes) that enable a more robust and unambiguous evaluation of consistency. This targeted approach ensures that our prompts do not depend on external associations, making the evaluation both clearer and more reliable.

% In our evaluation, we determined that setting the guidance scale ($\eta$) to 0.3 was optimal for generating high-quality images, as higher guidance levels resulted in blurred outputs even when augmented with high-resolution cues like “4K” or “UHD.” Furthermore, at a mixing weight ($\alpha$) of 0.7, the model successfully protected itself from generating overly similar copyrighted images, while still remaining consistent with the target concept's defining characteristics. This was evidenced by a CLIP-I score of approximately 0.84 between protected and unprotected images—a score that suggests the protected image is neither too similar to the unprotected version nor too inconsistent with the intended target. These results validate our indirect anchoring method, demonstrating that descriptive prompts focusing on key visual traits allow the model to accurately capture and replicate the essence of cartoon characters while mitigating direct associations that might otherwise lead to copyright infringement.

\begin{table}[t]
    \centering
    \scalebox{0.7}{
    \begin{tabular}{c|cccccc} % 8 columns
        \toprule
        $\alpha$ & SSIM & LPIPS & CLIP-I & CLIP-T & CONS & DETECT
        \\ 
        \midrule
        0.60 & 0.53 & 0.48 & 0.86 & 0.20 & 0.70 & 8 \\
        0.65 & \textbf{0.56} & 0.50 & \textbf{0.86} & 0.20 & 0.71 & 8 \\
        0.70 & 0.50 & \textbf{0.53} & 0.84 & \textbf{0.22} & \textbf{0.74} & 3 \\
        0.75 & 0.52 & 0.52 & 0.82 & 0.21 & 0.67 & \textbf{2} \\
        \bottomrule
    \end{tabular}
    }
    \caption{Results with \textit{indirect anchoring} at $\eta = 3.0$ in FLUX model}
    \label{tab:Flux_indirect_anchoring}
    \vspace{-1\baselineskip}
\end{table}

\textbf{Complex prompt analysis:} We employed complex prompts featuring multiple concepts and challenging backgrounds that could distract the model from the intended target, potentially leading to copyrighted outputs. Our GoG method effectively mitigates this issue, maintaining the integrity of other objects and settings (see Figure~\ref{fig:complex-flux} for reference). These results underscore our approach's strong potential to handle complex prompts without infringing on copyright.\par

% In contrast, if the model were to generate random images without considering the user's prompt, we would expect the evaluation metrics to differ significantly—for example, CLIP-T scores would likely drop substantially, indicating poor alignment with any intended semantic content, and CLIP-I values might vary erratically. Additionally, perceptual measures like LPIPS and structural metrics such as SSIM would not exhibit the moderate, consistent ranges we observe, as random generations would lack both coherent semantic cues and controlled modifications relative to the originals. The consistency of our reported values confirms that our approach successfully preserves the user’s prompt intent while simultaneously ensuring that the generated images are sufficiently altered from the copyrighted source, thus effectively balancing both conditions.

\textbf{Time cost analysis:} Table~\ref{tab:time_cost_per_generation} shows that, on a single NVIDIA A6000 GPU, generation times without GoG range from 35.84 to 56.63 seconds, while with GoG they increase to between 185.27 and 251.02 seconds. Although this adds significant overhead, the improved control over output quality and copyright compliance justifies the extra time. Future optimizations could reduce latency for real-time applications.

\begin{table}[t]
\centering
\scalebox{0.9}{
\begin{tabular}{c c}
 \hline
 Prompt Lengths & Frequency \\
 \toprule
 $1 \leq \;p_{len} < 10$ & 51   \\
 \midrule
 $10 \leq \;p_{len} < 20$ & 37\\
  \midrule
 $20 \leq \;p_{len}$ & 11 \\
 \bottomrule
\end{tabular}}
\caption{Distribution of prompt lengths in the evaluation dataset}
\label{tab:distri_prompt_len}
\vspace{-1\baselineskip}
\end{table}


% \begin{table}[t]
% \centering
% \resizebox{\columnwidth}{!}{
% \begin{tabular}{c c}
%  \hline
%  Model & Time Cost (seconds) per generation \\
%  \toprule
%  SD 2.1 \cite{sd} & 37.25\\
%  SDXL \cite{sdxl} & 39.75\\
%  FLUX.1-dev \cite{blackforestlabs2024flux} & 103.0\\
%  \bottomrule
% \end{tabular}
% }
% \caption{Averaged time cost per generation for evaluated models using single NVIDIA A6000 GPUs.}
% \label{tab:time_cost_per_generation}
% \end{table}

\begin{table}[t]
\centering
\scalebox{0.8}{
\begin{tabular}{c | c c}
\hline
\multirow{2}{*}{Model} & \multicolumn{2}{c}{Time cost (seconds) per generation} \\
\cline{2-3}
 & w/o GoG & with GoG \\
\toprule
SD 2.1 \cite{sd}           & 35.84  & 185.27 \\
SDXL \cite{sdxl}           & 38.92  & 187.77  \\
FLUX.1-dev \cite{blackforestlabs2024flux} & 56.63  & 251.02  \\
\bottomrule
\end{tabular}
}
\caption{Average time cost per generation with and without GoG using single NVIDIA A6000 GPU.}
\label{tab:time_cost_per_generation}
\vspace{-1\baselineskip}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{Images/actors_potraits.png}
    \caption{Before and after \textbf{GoG} generated portraits of well-known celebrities: Elon Musk, Leonardo DiCaprio, Emma Stone, Dwayne Johnson}
    \label{fig:celeb}
    \vspace{-1\baselineskip}
\end{figure}


